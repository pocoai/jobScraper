{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape jobs from ai-jobs.net\n",
    "# import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import scrapy\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the html\n",
    "ai_jobs_url = 'https://ai-jobs.net/'\n",
    "ai_jobs_response = requests.get(ai_jobs_url)\n",
    "ai_jobs_soup = BeautifulSoup(ai_jobs_response.content, 'html5lib')\n",
    "\n",
    "print(ai_jobs_soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the job list stored in ul tag with job-list id\n",
    "job_list = ai_jobs_soup.find('ul', attrs = {'id': 'job-list'})\n",
    "\n",
    "# get the job list items stored in li tags as next children of job_list\n",
    "job_list_items = job_list.findChildren('li', recursive = False)\n",
    "\n",
    "# get the job details from each job list item\n",
    "job_details = []\n",
    "\n",
    "# parse job description from apply link\n",
    "def parse_job_description_ai_jobs(url):\n",
    "    aijobs_job_page = requests.get(url)\n",
    "    aijobs_job_page_soup = BeautifulSoup(aijobs_job_page.content, 'html5lib')\n",
    "    job_description = aijobs_job_page_soup.find('div', attrs = {'id': 'job-description'}).decode_contents()\n",
    "    return job_description\n",
    "\n",
    "for job_list_item in job_list_items:\n",
    "    job_detail = {}\n",
    "    # get the job title stored in h3 tag\n",
    "    job_detail['title'] = job_list_item.find('h3').text\n",
    "\n",
    "    # store div.float-end as a variable\n",
    "    float_end = job_list_item.find('div', attrs = {'class': 'float-end'})\n",
    "\n",
    "    # get the job type stored in span tag with tex-bg-background inside div tag with class float-end\n",
    "    job_detail['type'] = float_end.find('span', attrs = {'class': 'text-bg-secondary'}).text\n",
    "\n",
    "    # get the job location stored in span tag with d-md-block inside div tag with class float-end\n",
    "    job_detail['location'] = float_end.find('span', attrs = {'class': 'd-md-block'}).text\n",
    "\n",
    "    # get all the div tag with class d-block\n",
    "\n",
    "    div_d_block = job_list_item.find_all('div', attrs = {'class': 'd-block'})\n",
    "    # get the count of div tags with class float-end\n",
    "    div_count = len(div_d_block)\n",
    "    job_salary = div_d_block[div_count - 1].find('span', attrs = {'class': 'text-bg-success'})\n",
    "\n",
    "    # check if job_salary is not None\n",
    "    if job_salary is not None:\n",
    "        # print(div_count, job_salary.text)\n",
    "\n",
    "        # get the salary_start and salary_end from the job_salary string stored in this format -> USD 80K - 110K\n",
    "        # remove the USD/GBP or three lettered currency using regex from the string\n",
    "        job_salary = re.sub(r'[A-Z]{3}', '', job_salary.text)\n",
    "\n",
    "        # split the string by 'K' and get the first element for salary_start with space removed\n",
    "        job_detail['salary_start'] = int(job_salary.split('K')[0].strip())\n",
    "\n",
    "        # check if salary_end is present in the string by checking if the string contains '-'\n",
    "        if '-' in job_salary:\n",
    "            # split the string by '-' and get the second element for salary_end\n",
    "            job_detail['salary_end'] = int(job_salary.split('-')[1].split('K')[0].strip())\n",
    "        else:\n",
    "            job_detail['salary_end'] = int(job_detail['salary_start'])\n",
    "\n",
    "        # print(job_detail['salary_start'], job_detail['salary_end'])\n",
    "    else:\n",
    "        job_detail['salary_start'] = 00\n",
    "        job_detail['salary_end'] = 00\n",
    "\n",
    "    # get the job link stored in a tag with title attribute\n",
    "    job_detail['website_link'] = job_list_item.find('a', attrs = {'title': 'View details for this job'})['href']\n",
    "\n",
    "    # get the external job link from website_link\n",
    "    # /job/42991-ai-content-creator/ -> https://ai-jobs.net/J42991/apply/\n",
    "    job_detail['apply_link'] = 'https://ai-jobs.net' + job_detail['website_link'].replace('job/', 'J').split('-')[0] + '/apply/'\n",
    "    # can't get the job description from the website\n",
    "    job_detail['description'] = ''\n",
    "\n",
    "    print(job_detail['description'])\n",
    "    # tags for the job \n",
    "    # get all the span.text-bg-light tags upto 5th index\n",
    "    tags = job_list_item.find_all('span', attrs = {'class': 'text-bg-light'})[:5]\n",
    "    job_detail['tags'] = [i.text for i in tags]\n",
    "\n",
    "    job_details.append(job_detail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the job description with the parsed job description\n",
    "for job in job_details:\n",
    "    job['description'] = parse_job_description_ai_jobs('https://ai-jobs.net'+ job_detail['website_link'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the job details in a json file\n",
    "with open('ai-jobs.json', 'w') as f:\n",
    "    json.dump(job_details, f, indent = 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get MachineHack jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# await fetch(\"https://bootcamp.prod.machinehack.com/jobs/getAllJobs?current_page=1\", {\n",
    "#     \"credentials\": \"omit\",\n",
    "#     \"headers\": {\n",
    "#         \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/109.0\",\n",
    "#         \"Accept\": \"application/json, text/plain, */*\",\n",
    "#     },\n",
    "#     \"referrer\": \"https://machinehack.com/\",\n",
    "#     \"method\": \"GET\",\n",
    "# });\n",
    "\n",
    "# equivalent python code for the above fetch request\n",
    "machinehack_url = 'https://bootcamp.prod.machinehack.com/jobs/getAllJobs?current_page=1'\n",
    "machinehack_response = requests.get(machinehack_url, headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/109.0', 'Accept': 'application/json, text/plain, */*'})\n",
    "machinehack_response = machinehack_response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "# \t\"0\": {\n",
    "# \t\t\"_id\": \"63e6346c3b5cfc0adbefe0b7\",\n",
    "# \t\t\"experienceRequired\": {\n",
    "# \t\t\t\"start\": 3,\n",
    "# \t\t\t\"end\": 5\n",
    "# \t\t},\n",
    "# \t\t\"AnnualSalaryRange\": {\n",
    "# \t\t\t\"start\": 0\n",
    "# \t\t},\n",
    "# \t\t\"timestamps\": {\n",
    "# \t\t\t\"created_at\": \"2023-02-10T12:11:24.000Z\",\n",
    "# \t\t\t\"updated_at\": \"2023-02-10T12:15:56.000Z\"\n",
    "# \t\t},\n",
    "# \t\t\"skills\": [\n",
    "# \t\t\t\"Risk\",\n",
    "# \t\t\t\"Modeling\",\n",
    "# \t\t\t\"Credit Risk\",\n",
    "# \t\t\t\"ECL\",\n",
    "# \t\t\t\"Validation\"\n",
    "# \t\t],\n",
    "# \t\t\"location\": [\n",
    "# \t\t\t\"Bangalore Urban\"\n",
    "# \t\t],\n",
    "# \t\t\"publishedAt\": \"2023-02-10T12:15:56.000Z\",\n",
    "# \t\t\"questions\": [],\n",
    "# \t\t\"jobTitle\": \"Data Scientist\",\n",
    "# \t\t\"jobDescription\": \"<p>Credit Risk Model Developer</p><p>&nbsp;</p><p><strong>Experience: 3-5Y Responsibilities:</strong></p><p>&nbsp;</p><p>• Build, validate, document, implement and rebuild:<br>o Credit risk models (retail loan origination models, business banking customer rating</p><p>models, and loan behaviour scorecards)<br>o Collective Provision and Expected Loss methodologies. This includes all inputs of</p><p>Probability of Default, Loss Given Default and Exposure at Default (methodology).&nbsp;</p><p>&nbsp;</p><p>• Conduct detailed analytical work with a high level of accuracy in order to deliver high level</p><p>results to senior management and contribute to the management and education of enhanced credit risk approaches.</p><p>o Develop on going improvements to the model reporting.</p><p>o Responsible for managing issues through to resolution.</p><p>&nbsp;</p><p>• Define and specify key data requirements to support modelling approaches.</p><p>• Document model “technical manual”, modelling choices made, and model methodology</p><p>considerations.</p><p>• Engage with operational risk advisory, quantitative analyst, reporting and regulatory</p><p>specialist stakeholders.</p><p>• Assist in the development of other Credit Risk Modelling team members.</p><p>&nbsp;</p><p>• Working with credit risk Model Development Leaders to:</p><p>o Proactively engage with stakeholders to understand business context, add value, propose solutions, project manage pieces of work through to completion.</p><p>o Balance prioritization effectively between across a wide stakeholder group. Ensure time spent matches the importance of the work and manage situations / competing priorities so that the most beneficial program of work is achieved.</p><p>&nbsp;</p><p>• Working with the leaders of the Credit Risk Modelling team to ensure:<br>o Models are effectively embedded into operational activities<br>o The program of work for the department is documented and resourcing or delivery</p><p>issues are well managed.</p><p>&nbsp;</p><p>• Prepare and review analysis papers and ensure that high quality analytical papers are</p><p>written and delivered to appropriate senior management and committees. Present these</p><p>papers in an effective manner appropriate to the audience.</p><p>&nbsp;</p><p>• Analyse and constructively critique output across the wider Banking Credit function for the</p><p>business impacts (including regulatory and external audit) to ensure committee papers consider portfolio, modelling and data risks, and ultimately propose strategic recommendations that are underpinned by a compelling case.</p><p>&nbsp;</p><p>• Identifying inefficiencies and proposing operational process improvements to enable better outcomes.</p><p>• Add value to deliverables with excellent problem solving, idea generation and strategic thinking. Work closely with the wider Advanced Basel Project team, Banking Credit and other senior managers and Team Leaders. Active engagement in discussions with senior management to optimize the best solution for the bank and group.</p>\",\n",
    "# \t\t\"slug\": \"data-scientist-da974\",\n",
    "# \t\t\"jobType\": \"Permanent\",\n",
    "# \t\t\"workType\": \"Hybrid\",\n",
    "# \t\t\"postedBy\": {\n",
    "# \t\t\t\"_id\": \"627b3f6a23e5b51a29d5cc4b\",\n",
    "# \t\t\t\"firstName\": \"Sufiyan\",\n",
    "# \t\t\t\"lastName\": \"S\"\n",
    "# \t\t},\n",
    "# \t\t\"companyId\": {\n",
    "# \t\t\t\"_id\": \"6152a94e0ad6636dbf06081b\",\n",
    "# \t\t\t\"companyName\": \"AIM Recruits\",\n",
    "# \t\t\t\"timestamps\": {\n",
    "# \t\t\t\t\"created_at\": \"2021-09-28T05:34:06.655Z\",\n",
    "# \t\t\t\t\"updated_at\": \"2022-05-19T03:59:32.233Z\"\n",
    "# \t\t\t},\n",
    "# \t\t\t\"logo\": \"https://machinehack-enterprise-prod.s3.ap-south-1.amazonaws.com/machine_hack/production%20files/Machine_Hack__PLNNY__uploaded_at_1652687008014.jpeg\",\n",
    "# \t\t\t\"website\": \"https://recruits.analyticsindiamag.com/\"\n",
    "# \t\t},\n",
    "# \t\t\"views\": 1,\n",
    "# \t\t\"applicants\": 0\n",
    "# \t}\n",
    "# }\n",
    "\n",
    "# reformat above json to job_details array\n",
    "job_details = []\n",
    "for job in machinehack_response['result']['data']:\n",
    "\n",
    "    job_details.append({\n",
    "        'id': job['_id'],\n",
    "        'title': job['jobTitle'],\n",
    "        'type': job['jobType'] if 'jobType' in job else 'Not mentioned',\n",
    "        'location': job['location'],\n",
    "        'salary_start': job['AnnualSalaryRange']['start'],\n",
    "        # if end salary is not mentioned, set it to start salary\n",
    "        'salary_end': job['AnnualSalaryRange']['end'] if 'end' in job['AnnualSalaryRange'] else job['AnnualSalaryRange']['start'],\n",
    "        'apply_link': 'https://machinehack.com/jobs/?currentJobId=' + job['_id'],\n",
    "        'description': job['jobDescription'],\n",
    "        'tags': job['skills'][:5],\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write .json results into a file\n",
    "with open('machinehack_jobs.json', 'w') as f:\n",
    "    json.dump(job_details, f, indent = 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get mlconf jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# await fetch(\"https://mlconf.com/jm-ajax/get_listings/\", {\n",
    "#     \"headers\": {\n",
    "#         \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/109.0\",\n",
    "#         \"Accept\": \"*/*\",\n",
    "#         \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\"\n",
    "#     },\n",
    "#     \"referrer\": \"https://mlconf.com/jobs/\",\n",
    "#     \"body\": \"lang=&search_keywords=&search_location=&per_page=534&orderby=featured&order=DESC&page=1&show_pagination=false&form_data=search_keywords%3D%26search_location%3D\",\n",
    "#     \"method\": \"POST\",\n",
    "# })\n",
    "\n",
    "# equivalent to above fetch request\n",
    "# max_jobs = 534  // at current time, would certainly change in future\n",
    "# max number of jobs found out by passing 1 as value and response gives total number of pages which is 534\n",
    "\n",
    "# create a function to get jobs from a page\n",
    "def get_jobs(jobs_count):\n",
    "    mlconf_response = requests.post('https://mlconf.com/jm-ajax/get_listings/', data = {\n",
    "        'lang': '',\n",
    "        'search_keywords': '',\n",
    "        'search_location': '',\n",
    "        'per_page': jobs_count, \n",
    "        'orderby': 'featured',\n",
    "        'order': 'DESC',\n",
    "        'page': 1,\n",
    "        'show_pagination': 'false',\n",
    "        'form_data': 'search_keywords=&search_location='\n",
    "    })\n",
    "    return mlconf_response.json()\n",
    "\n",
    "# get jobs count from response by reading max_num_pages key from response when per_page is 1\n",
    "jobs_count_current = get_jobs(1)['max_num_pages']\n",
    "print(jobs_count_current)\n",
    "# get all jobs with jobs_count\n",
    "mlconf_response = get_jobs(jobs_count_current)\n",
    "\n",
    "print(mlconf_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse out html from response\n",
    "soup = BeautifulSoup(mlconf_response['html'], 'html5lib')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat above html to separate out each job\n",
    "# select all li tags with class job_listing\n",
    "mlconf_job_listings = soup.select('li.type-job_listing')\n",
    "# print(mlconf_job_listings)\n",
    "\n",
    "job_details = []\n",
    "for job in mlconf_job_listings:\n",
    "    # get job title from h3 tag\n",
    "    job_title = job.find('h3').text.strip()\n",
    "    # get job type from class name among multiple classes of li tag job-type-*\n",
    "    # <li class=\"post-15783 job_listing type-job_listing status-publish has-post-thumbnail entry job-type-full-time\" data-latitude=\"\" data-longitude=\"\">\n",
    "    # for above example, job type is full-time\n",
    "    # get all classes of li tag\n",
    "    li_classes = job['class']\n",
    "    # get job type class from li_classes\n",
    "    job_type = [type_class for type_class in li_classes if 'job-type-' in type_class]\n",
    "    \n",
    "    # if job type is not mentioned, set it to 'Not mentioned'\n",
    "    if len(job_type) == 0:\n",
    "        job_type = 'Not mentioned'\n",
    "    else:\n",
    "        # get job type from job_type list\n",
    "        job_type = job_type[0].split('-')[2]\n",
    "\n",
    "    # get job location from div tag with class location\n",
    "    job_location = job.find('div', class_ = 'location').text.strip()\n",
    "    # doesn't have salary info\n",
    "    job_salary_start = 00\n",
    "    job_salary_end = 00\n",
    "    # get job apply link from a tag\n",
    "    job_apply_link = job.find('a')['href']\n",
    "    # Doesn't have job description\n",
    "    job_description = ''\n",
    "    # Doesn't have tags/skills/keywords\n",
    "    job_tags = []\n",
    "\n",
    "    job_details.append({\n",
    "        'title': job_title,\n",
    "        'type': job_type,\n",
    "        'location': job_location,\n",
    "        'salary_start': job_salary_start,\n",
    "        'salary_end': job_salary_end,\n",
    "        'website_link': job_apply_link,\n",
    "        'description': job_description,\n",
    "        'tags': job_tags,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get jobs from a page\n",
    "def get_job_description_mlconf(url):\n",
    "    mlconf_response = requests.get(url)\n",
    "    mlconf_soup = BeautifulSoup(mlconf_response.content, 'html5lib')\n",
    "    # get job description from div tag with class job_description\n",
    "    job_description = mlconf_soup.find('div', class_ = 'job_description').decode_contents()\n",
    "    job_link = mlconf_soup.find('div', class_ = 'application_details').findChild('a')['href']\n",
    "    return job_description, job_link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get jobs description from job apply link\n",
    "# store failure as jobs started expiring in exception\n",
    "count = 0\n",
    "# iterate over job_details and get job description from apply link if count < 5\n",
    "for job in job_details:\n",
    "    if count < 5:\n",
    "        try:\n",
    "            job['description'], job['apply_link'] = get_job_description_mlconf(job['website_link'])\n",
    "        except:\n",
    "            job['description'] = ''\n",
    "            count += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write .json results into a file\n",
    "with open('mlconf_jobs.json', 'w') as f:\n",
    "    json.dump(job_details, f, indent = 4)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get jobs from datajobs.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get response from initial html response\n",
    "datajobs_url = 'https://datajobs.com/Data-Science-Jobs'\n",
    "datajobs_response = requests.get(datajobs_url)\n",
    "\n",
    "# parse out html from response\n",
    "soup = BeautifulSoup(datajobs_response.content, 'html5lib')\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get div tag with style attribute and value as 'display: table-cell'\n",
    "# this consists of all job listings\n",
    "datajobs_job_listings = soup.find('div', attrs = {'style': 'display:table-cell; width:520px;'})\n",
    "# print(datajobs_job_listings.prettify())\n",
    "\n",
    "# get all div tags within datajobs_job_listings nonrecursively leaving out last div tag\n",
    "datajobs_job_listings = datajobs_job_listings.find_all('div', recursive = False)[:-1]\n",
    "\n",
    "job_details = []\n",
    "\n",
    "# get all job details from datajobs_job_listings\n",
    "for job in datajobs_job_listings:\n",
    "    # get a tag within job div\n",
    "    job_a_tag = job.find('a')\n",
    "    # get job title from strong tag within a tag\n",
    "    job_title = job_a_tag.find('strong').text.strip()\n",
    "    # doesn't have job type\n",
    "    job_type = 'Not mentioned'\n",
    "    # get location from em tag within job div\n",
    "    job_location = job.find('em').text.strip().split('\\n')[0]\n",
    "    # check if salary is mentioned in job em tag\n",
    "    if '\\u2013' in job.find('em').text.strip():\n",
    "        # get salary from job_location\n",
    "        job_salary_start = int(job.find('em').text.split('$')[1].split('\\u2013')[0].strip().split(',')[0])\n",
    "        # print(\"job_salary_start\", job_salary_start)\n",
    "        job_salary_end = int(job.find('em').text.split('$')[2].split('\\n')[0].strip().split(',')[0])\n",
    "        # get end salary if mentioned\n",
    "    else:\n",
    "        # doesn't have salary info\n",
    "        job_salary_start = 00\n",
    "        job_salary_end = 00\n",
    "\n",
    "    # get job apply link from href attribute of a tag\n",
    "    website_link = \"https://datajobs.com\" + job_a_tag['href']\n",
    "\n",
    "    # create id for job\n",
    "    job_id = website_link.split('~')[-1]\n",
    "\n",
    "    # doesn't have job description\n",
    "    job_description = ''\n",
    "    # doesn't have tags/skills/keywords\n",
    "    job_tags = []\n",
    "\n",
    "    job_details.append({\n",
    "        'id': job_id,\n",
    "        'title': job_title,\n",
    "        'type': job_type,\n",
    "        'location': job_location,\n",
    "        'salary_start': job_salary_start,\n",
    "        'salary_end': job_salary_end,\n",
    "        'website_link': website_link,\n",
    "        'apply_link': '',\n",
    "        'description': job_description,\n",
    "        'tags': job_tags,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get job description from job apply link\n",
    "def get_job_description_datajobs(url):\n",
    "    datajobs_response = requests.get(url)\n",
    "    datajobs_soup = BeautifulSoup(datajobs_response.content, 'html5lib')\n",
    "    # get job description from first div tag with class jobpost-table-cell-2\n",
    "    job_description = datajobs_soup.find('div', class_ = 'jobpost-table-cell-2').decode_contents()\n",
    "    return job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get job apply link from website link\n",
    "def get_job_apply_link_datajobs(job_id):\n",
    "    # create request url for apply link from job id\n",
    "    url = 'https://datajobs.com/job-posting-applyto-ajax?job_id='+job_id\n",
    "    # get response from request url\n",
    "    datajobs_response = requests.get(url)\n",
    "    # parse out html from response\n",
    "    datajobs_soup = BeautifulSoup(datajobs_response.content, 'html5lib')\n",
    "    # get job apply link from href attribute of a tag\n",
    "    print(datajobs_soup.prettify(), job_id, url)\n",
    "    job_apply_link = datajobs_soup.find('a')['href']\n",
    "    return job_apply_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in job_details:\n",
    "    job['description'] = get_job_description_datajobs(job['website_link'])\n",
    "    job['apply_link'] = get_job_apply_link_datajobs(job['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write .json results into a file\n",
    "with open('datajobs_jobs.json', 'w') as f:\n",
    "    json.dump(job_details, f, indent = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
